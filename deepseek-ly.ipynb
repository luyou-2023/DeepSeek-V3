{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:18:24.540699Z","iopub.execute_input":"2025-02-28T02:18:24.540888Z","iopub.status.idle":"2025-02-28T02:21:37.041252Z","shell.execute_reply.started":"2025-02-28T02:18:24.540868Z","shell.execute_reply":"2025-02-28T02:21:37.039970Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"huggingface\")\nlogin(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:22:54.222594Z","iopub.execute_input":"2025-02-28T02:22:54.222878Z","iopub.status.idle":"2025-02-28T02:22:55.121513Z","shell.execute_reply.started":"2025-02-28T02:22:54.222854Z","shell.execute_reply":"2025-02-28T02:22:55.120890Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import wandb\n\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='DeepSeek-R1-8B Test', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:23:18.397955Z","iopub.execute_input":"2025-02-28T02:23:18.398246Z","iopub.status.idle":"2025-02-28T02:23:32.903947Z","shell.execute_reply.started":"2025-02-28T02:23:18.398223Z","shell.execute_reply":"2025-02-28T02:23:32.903335Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluyou042\u001b[0m (\u001b[33mluyou042-org\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250228_022326-vqdhopmw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/luyou042-org/DeepSeek-R1-8B%20Test/runs/vqdhopmw' target=\"_blank\">still-deluge-1</a></strong> to <a href='https://wandb.ai/luyou042-org/DeepSeek-R1-8B%20Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/luyou042-org/DeepSeek-R1-8B%20Test' target=\"_blank\">https://wandb.ai/luyou042-org/DeepSeek-R1-8B%20Test</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/luyou042-org/DeepSeek-R1-8B%20Test/runs/vqdhopmw' target=\"_blank\">https://wandb.ai/luyou042-org/DeepSeek-R1-8B%20Test/runs/vqdhopmw</a>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\n# 设置模型的最大 序列长度（即每次输入的最大 token 数量）。\n# 2048 适合 长文本处理，对于像 Llama 或 DeepSeek 这样的模型，处理大规模数据时可以提高训练效果。\nmax_seq_length = 2048 \n\n# 该参数用于设置模型的数据类型\n# None 表示 自动选择数据类型。\n# 如果你希望使用 半精度训练（FP16 或 BF16），可以通过设置此参数来指定。\ndtype = None \n\n# 4-bit 量化：加载模型时启用 4-bit 量化，使得模型参数存储为 4-bit，从而显著降低显存占用。\n# 量化是为了在显存受限的设备上运行大模型。启用量化会在不显著降低性能的情况下减少内存使用。\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",    # 指定要加载的模型名称\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:24:31.199629Z","iopub.execute_input":"2025-02-28T02:24:31.199953Z","iopub.status.idle":"2025-02-28T02:25:37.320113Z","shell.execute_reply.started":"2025-02-28T02:24:31.199922Z","shell.execute_reply":"2025-02-28T02:25:37.319236Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc57f81691d42a989d2b953fa4c9ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"622c311207654eca86710de9673fa087"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5a7cc89639b471c86dbff3a1f3f8920"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1299e95dc72a411196fd49487da6ab13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b28155845ed44bd94ed727a2808b380"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:26:10.195023Z","iopub.execute_input":"2025-02-28T02:26:10.195421Z","iopub.status.idle":"2025-02-28T02:26:10.200550Z","shell.execute_reply.started":"2025-02-28T02:26:10.195392Z","shell.execute_reply":"2025-02-28T02:26:10.199672Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"question = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n\n# 准备模型推理\nFastLanguageModel.for_inference(model) \n\n# 将问题格式化并转换为模型可以理解的输入格式\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# 生成回答\noutputs = model.generate(\n    # 输入的 token IDs，来自之前 tokenizer 转换的结果\n    input_ids=inputs.input_ids,    \n    # 用于标记哪些 token 需要注意，避免模型在无关区域做出不必要的计算。\n    attention_mask=inputs.attention_mask,   \n    # 生成的最大 token 数量为 1200，这意味着模型最多会生成 1200 个 token 的回答\n    max_new_tokens=1200,    \n    # 启用缓存，优化推理速度。\n    use_cache=True,    \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:27:07.470287Z","iopub.execute_input":"2025-02-28T02:27:07.470601Z","iopub.status.idle":"2025-02-28T02:28:18.849760Z","shell.execute_reply.started":"2025-02-28T02:27:07.470578Z","shell.execute_reply":"2025-02-28T02:28:18.848768Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"response = tokenizer.batch_decode(outputs)    # 将生成的 token IDs 转换为文本（字符串）\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:34:56.152661Z","iopub.execute_input":"2025-02-28T02:34:56.152970Z","iopub.status.idle":"2025-02-28T02:34:56.160623Z","shell.execute_reply.started":"2025-02-28T02:34:56.152947Z","shell.execute_reply":"2025-02-28T02:34:56.159813Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I have this medical case to think through. Let's see, the patient is a 61-year-old woman with a history of involuntary urine loss when she coughs or sneezes, but she doesn't leak at night. She's had a gynecological exam and a Q-tip test. I need to figure out what cystometry would show regarding her residual volume and detrusor contractions.\n\nFirst, I should break down the information given. The patient has urinary incontinence, specifically during activities that involve coughing or sneezing. That makes me think of stress urinary incontinence, which is usually due to the urethral sphincter not closing properly during these activities. But since she doesn't leak at night, it's less likely to be a case of genuine stress incontinence, which often affects women during sleep.\n\nNow, she underwent a gynecological exam. I'm assuming that this exam might have included a pelvic exam, possibly looking for pelvic floor muscle tone, bladder size, and other structural issues. The Q-tip test is a common diagnostic tool for stress urinary incontinence. The Q-tip is a small catheter used to measure the closure pressure of the urethral sphincter. If the pressure is low, it suggests that the sphincter isn't closing properly, leading to incontinence.\n\nSince she has a long history of involuntary loss during activities like coughing, the Q-tip test likely showed low closure pressure, indicating a sphincter defect. This would support a diagnosis of stress urinary incontinence.\n\nNow, considering the findings from the gynecological exam and the Q-tip test, what would cystometry reveal? Cystometry, also known as a bladder chart, is a diagnostic procedure where the patient is asked to perform activities that may trigger incontinence (like coughing, sneezing) while a catheter is in place to measure bladder pressure and volume.\n\nIn a normal individual, the detrusor (the muscle layer of the bladder) contracts when the bladder is full, and this contraction should lead to an increase in pressure, which then triggers the release of urine via the urethral sphincter. In someone with stress urinary incontinence, the detrusor contractions may be normal in terms of pressure but the sphincter doesn't close properly, leading to leakage.\n\nHowever, in cases where there's a significant issue with the detrusor itself, such as impaired contractility, the detrusor contractions might be weak or absent. This would be important because if the detrusor can't contract properly, it might lead to retention of urine or not emptying the bladder completely, which can cause urinary retention or other issues.\n\nIn this case, since the patient's problem is more about the sphincter not closing (as shown by the Q-tip test), the detrusor contractions themselves are likely normal. However, if the gynecological exam showed that the detrusor muscle has impaired contractility, then the cystometry would show weak or absent contractions, leading to problems with emptying the bladder.\n\nBut wait, the question is specifically about residual volume and detrusor contractions. So, residual volume refers to the volume of urine remaining in the bladder after a normal void. If the patient has impaired contractility, the residual volume might increase because the bladder doesn't empty completely. But in this case, the primary issue is stress incontinence, which is more about the sphincter, not the detrusor contractility. So, the detrusor contractions would be normal, but the residual volume might be normal as well, unless there's a separate issue causing retention.\n\nAlternatively, if the patient has an overactive bladder, the detrusor contractions would be increased, leading to urgency and possibly incontinence. But the question doesn't mention urgency, just the involuntary loss during specific activities.\n\nSo, putting it all together, the cystometry would likely show normal detrusor contractions, as the problem lies in the sphincter closure. However, the residual volume would depend on whether there's any retention or not. Since the patient doesn't leak at night, it's possible that her residual volume is within normal limits, and the detrusor contractions are normal.\n\nWait, but the question is specifically about what cystometry would reveal about residual volume and detrusor contractions based on the findings from the gynecological exam and Q-tip test. So, the findings from the Q-tip test suggest sphincter insufficiency, not detrusor issue. Therefore, the detrusor contractions would be normal, and the residual volume would be normal as well unless there's another cause for retention.\n\nSo, in conclusion, cystometry would show normal detrusor contractions and normal residual volume, indicating that the primary issue is with the sphincter, not the detrusor.\n</think>\n\nBased on the provided information and the thought process, the cystometry results for the 61-year-old woman would reveal:\n\n**Detrusor Contractions:** Normal\n\n**Residual Volume:** Normal\n\n**Conclusion:** The primary issue identified is stress urinary incontinence due to sphincter insufficiency, as evidenced by the Q-tip test results. The detrusor contractions and residual volume are normal, indicating that the problem lies within the sphincter rather than the detrusor muscle.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:35:25.360763Z","iopub.execute_input":"2025-02-28T02:35:25.361042Z","iopub.status.idle":"2025-02-28T02:35:25.365551Z","shell.execute_reply.started":"2025-02-28T02:35:25.361021Z","shell.execute_reply":"2025-02-28T02:35:25.364715Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token  # 结束标记（End of Sequence）\n\ndef formatting_prompts_func(examples):\n    inputs = examples[\"Question\"]     # 取出问题\n    cots = examples[\"Complex_CoT\"]    # 取出复杂推理过程（CoT）\n    outputs = examples[\"Response\"]    # 取出回答\n    texts = []    # 存储格式化后的文本\n    \n    for input, cot, output in zip(inputs, cots, outputs):\n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n        texts.append(text)\n        \n    return {\n        \"text\": texts,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:35:56.373923Z","iopub.execute_input":"2025-02-28T02:35:56.374272Z","iopub.status.idle":"2025-02-28T02:35:56.379955Z","shell.execute_reply.started":"2025-02-28T02:35:56.374239Z","shell.execute_reply":"2025-02-28T02:35:56.379199Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from datasets import load_dataset\n\n# 加载数据集\ndataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\"en\", split = \"train[0:500]\",trust_remote_code=True)\n\n# 应用自定义的格式化函数\ndataset = dataset.map(formatting_prompts_func, batched = True,)\n\n# 查看处理后的数据集的第一个文本样本\ndataset[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:36:37.557496Z","iopub.execute_input":"2025-02-28T02:36:37.557808Z","iopub.status.idle":"2025-02-28T02:36:40.725754Z","shell.execute_reply.started":"2025-02-28T02:36:37.557780Z","shell.execute_reply":"2025-02-28T02:36:40.725075Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54d5afbf19284682999fc4ce32e605ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/74.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fcee38cced44fc1843668e098ba7a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25371 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f8ece1b4864b4aa5f060e48e59ddaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab14f39cb7640d898eca35b264b7132"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n\\n### Question:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Response:\\n<think>\\nOkay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\\n</think>\\nCystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.<｜end▁of▁sentence｜>\""},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,    # 需要进行 LoRA 微调 的 LLM\n    r=16,    # LoRA 低秩矩阵的秩值，决定参数更新规模（推荐 8 或 16）\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,    # LoRA scaling factor（影响学习率）\n    lora_dropout=0,     # oRA dropout（0 代表不开启）\n    bias=\"none\",      # 是否对 LoRA 进行偏置微调（none 表示不训练偏置）\n    use_gradient_checkpointing=\"unsloth\",  # 开启梯度检查点，节省显存（用于长上下文训练）\n    random_state=3407,    # 设置随机种子，保证实验结果可复现\n    use_rslora=False,    # 是否使用 r-sLoRA（更高效的 LoRA 变体），False 代表不用  \n    loftq_config=None,    # 是否使用 LoftQ（量化 LoRA），None 代表关闭\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:38:40.396943Z","iopub.execute_input":"2025-02-28T02:38:40.397297Z","iopub.status.idle":"2025-02-28T02:38:46.823701Z","shell.execute_reply.started":"2025-02-28T02:38:40.397268Z","shell.execute_reply":"2025-02-28T02:38:46.822785Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"pip install unsloth==2024.12.12","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:44:17.360059Z","iopub.execute_input":"2025-02-28T02:44:17.360427Z","iopub.status.idle":"2025-02-28T02:44:22.309030Z","shell.execute_reply.started":"2025-02-28T02:44:17.360397Z","shell.execute_reply":"2025-02-28T02:44:22.308125Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth==2024.12.12\n  Downloading unsloth-2024.12.12-py3-none-any.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: unsloth_zoo>=2024.12.7 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (2025.2.7)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (2.6.0)\nRequirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.0.29.post3)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.45.3)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (24.2)\nRequirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.9.16)\nRequirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (4.49.0)\nRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (3.3.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (1.2.1)\nRequirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.15.2)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.29.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth==2024.12.12) (0.1.9)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth==2024.12.12) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth==2024.12.12) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth==2024.12.12) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth==2024.12.12) (3.11.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth==2024.12.12) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth==2024.12.12) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth==2024.12.12) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth==2024.12.12) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth==2024.12.12) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth==2024.12.12) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth==2024.12.12) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth==2024.12.12) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth==2024.12.12) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth==2024.12.12) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth==2024.12.12) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth==2024.12.12) (13.9.4)\nRequirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.12.7->unsloth==2024.12.12) (25.1.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.12.7->unsloth==2024.12.12) (11.0.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.12.12) (0.16)\nRequirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.12.12) (1.7.1)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth==2024.12.12) (4.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth==2024.12.12) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.12.12) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.12.12) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.12.12) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth==2024.12.12) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth==2024.12.12) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth==2024.12.12) (2.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth==2024.12.12) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth==2024.12.12) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth==2024.12.12) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth==2024.12.12) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth==2024.12.12) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth==2024.12.12) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth==2024.12.12) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth==2024.12.12) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth==2024.12.12) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth==2024.12.12) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth==2024.12.12) (1.17.0)\nDownloading unsloth-2024.12.12-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.7/175.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: unsloth\n  Attempting uninstall: unsloth\n    Found existing installation: unsloth 2025.2.15\n    Uninstalling unsloth-2025.2.15:\n      Successfully uninstalled unsloth-2025.2.15\nSuccessfully installed unsloth-2024.12.12\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,    # 负责 分词（保证训练数据格式正确）\n    train_dataset=dataset,    # 训练数据集（预处理后的 Hugging Face Dataset）\n    dataset_text_field=\"text\",    # 训练数据的 文本字段（例如 \"text\"）\n    max_seq_length=max_seq_length,    # 最大序列长度（如 2048）\n    dataset_num_proc=2,    # 数据预处理的 CPU 进程数（加速数据加载）\n    args=TrainingArguments(    # 训练参数\n        per_device_train_batch_size=2,    # 每块 GPU 的 batch size（小显存建议 2-4）\n        gradient_accumulation_steps=4,    # 梯度累积，相当于 batch size 放大 4x\n        warmup_steps=5,    # 预热步数，前 5 步学习率从 0 线性增加\n        max_steps=60,    # 训练 60 步（适用于快速测试）\n        learning_rate=2e-4,    # 默认 2e-4（LoRA 一般 2e-4 ~ 1e-5）\n        fp16=not is_bfloat16_supported(),    # NVIDIA A100/H100/4090 支持，训练更稳定\n        bf16=is_bfloat16_supported(),    # T4/V100/2080 不支持 BF16，改用 FP16\n        logging_steps=10,    # 每 10 步打印训练日志\n        optim=\"adamw_8bit\",    # 使用 8-bit AdamW，减少显存占用\n        weight_decay=0.01,    # L2 正则化，防止过拟合\n        lr_scheduler_type=\"linear\",    # 线性学习率衰减\n        seed=3407,    # 设定随机种子，保证实验可复现\n        output_dir=\"outputs\",    # 模型 & 训练日志保存路径\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:48:01.538695Z","iopub.execute_input":"2025-02-28T02:48:01.538984Z","iopub.status.idle":"2025-02-28T02:48:01.637407Z","shell.execute_reply.started":"2025-02-28T02:48:01.538963Z","shell.execute_reply":"2025-02-28T02:48:01.636240Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-3828147bec39>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0munsloth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_bfloat16_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m trainer = SFTTrainer(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# 负责 分词（保证训练数据格式正确）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/trainer.py\u001b[0m in \u001b[0;36mnew_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0moriginal_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_seq_length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'for_training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'tokenizer'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'padding_side'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_side\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'processing_class'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mfor_training\u001b[0;34m(model, use_gradient_checkpointing)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__delattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2038\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_register_state_dict_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: _unwrapped_old_generate"],"ename":"AttributeError","evalue":"_unwrapped_old_generate","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:47:05.622759Z","iopub.execute_input":"2025-02-28T02:47:05.623103Z","iopub.status.idle":"2025-02-28T02:47:05.657454Z","shell.execute_reply.started":"2025-02-28T02:47:05.623074Z","shell.execute_reply":"2025-02-28T02:47:05.656431Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-3d62c575fcfd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"],"ename":"NameError","evalue":"name 'trainer' is not defined","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"question = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n\n# 准备模型推理\nFastLanguageModel.for_inference(model) \n\n# 将问题格式化并转换为模型可以理解的输入格式\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# 生成回答\noutputs = model.generate(\n    # 输入的 token IDs，来自之前 tokenizer 转换的结果\n    input_ids=inputs.input_ids,    \n    # 用于标记哪些 token 需要注意，避免模型在无关区域做出不必要的计算。\n    attention_mask=inputs.attention_mask,   \n    # 生成的最大 token 数量为 1200，这意味着模型最多会生成 1200 个 token 的回答\n    max_new_tokens=1200,    \n    # 启用缓存，优化推理速度。\n    use_cache=True,    \n)\n\n# 解码生成的回答\nresponse = tokenizer.batch_decode(outputs)    # 将生成的 token IDs 转换为文本（字符串）\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:52:02.866755Z","iopub.execute_input":"2025-02-28T02:52:02.867051Z","iopub.status.idle":"2025-02-28T02:52:02.871675Z","shell.execute_reply.started":"2025-02-28T02:52:02.867029Z","shell.execute_reply":"2025-02-28T02:52:02.870823Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:52:15.570173Z","iopub.execute_input":"2025-02-28T02:52:15.570461Z","iopub.status.idle":"2025-02-28T02:52:24.873659Z","shell.execute_reply.started":"2025-02-28T02:52:15.570439Z","shell.execute_reply":"2025-02-28T02:52:24.872694Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.49.0.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"FastLanguageModel.for_training(model)\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  \n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0,  \n    bias=\"none\",  \n    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n    random_state=3407,\n    use_rslora=False,  \n    loftq_config=None,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:52:40.982664Z","iopub.execute_input":"2025-02-28T02:52:40.982981Z","iopub.status.idle":"2025-02-28T02:52:47.028550Z","shell.execute_reply.started":"2025-02-28T02:52:40.982951Z","shell.execute_reply":"2025-02-28T02:52:47.027893Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,    # 负责 分词（保证训练数据格式正确）\n    train_dataset=dataset,    # 训练数据集（预处理后的 Hugging Face Dataset）\n    dataset_text_field=\"text\",    # 训练数据的 文本字段（例如 \"text\"）\n    max_seq_length=max_seq_length,    # 最大序列长度（如 2048）\n    dataset_num_proc=2,    # 数据预处理的 CPU 进程数（加速数据加载）\n    args=TrainingArguments(    # 训练参数\n        per_device_train_batch_size=2,    # 每块 GPU 的 batch size（小显存建议 2-4）\n        gradient_accumulation_steps=4,    # 梯度累积，相当于 batch size 放大 4x\n        warmup_steps=5,    # 预热步数，前 5 步学习率从 0 线性增加\n        max_steps=60,    # 训练 60 步（适用于快速测试）\n        learning_rate=2e-4,    # 默认 2e-4（LoRA 一般 2e-4 ~ 1e-5）\n        fp16=not is_bfloat16_supported(),    # NVIDIA A100/H100/4090 支持，训练更稳定\n        bf16=is_bfloat16_supported(),    # T4/V100/2080 不支持 BF16，改用 FP16\n        logging_steps=10,    # 每 10 步打印训练日志\n        optim=\"adamw_8bit\",    # 使用 8-bit AdamW，减少显存占用\n        weight_decay=0.01,    # L2 正则化，防止过拟合\n        lr_scheduler_type=\"linear\",    # 线性学习率衰减\n        seed=3407,    # 设定随机种子，保证实验可复现\n        output_dir=\"outputs\",    # 模型 & 训练日志保存路径\n    ),\n)\n\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T02:53:54.323655Z","iopub.execute_input":"2025-02-28T02:53:54.323946Z","iopub.status.idle":"2025-02-28T03:17:39.872645Z","shell.execute_reply.started":"2025-02-28T02:53:54.323925Z","shell.execute_reply":"2025-02-28T03:17:39.871918Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Converting train dataset to ChatML (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6ede6753ce34128b7d73325ccdabaf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65a9bfac22e14228ad539dca6f89e1cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43bc735b76b746cfbbc5cf034479f89f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Truncating train dataset (num_proc=2):   0%|          | 0/500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d523cf1a460749bf8c14a5a584ca2ca5"}},"metadata":{}},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 500 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 23:02, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.918900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.461500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.402300</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.308800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.344300</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.314000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"question = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n\n# 准备模型推理\nFastLanguageModel.for_inference(model) \n\n# 将问题格式化并转换为模型可以理解的输入格式\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n# 生成回答\noutputs = model.generate(\n    # 输入的 token IDs，来自之前 tokenizer 转换的结果\n    input_ids=inputs.input_ids,    \n    # 用于标记哪些 token 需要注意，避免模型在无关区域做出不必要的计算。\n    attention_mask=inputs.attention_mask,   \n    # 生成的最大 token 数量为 1200，这意味着模型最多会生成 1200 个 token 的回答\n    max_new_tokens=1200,    \n    # 启用缓存，优化推理速度。\n    use_cache=True,    \n)\n\n# 解码生成的回答\nresponse = tokenizer.batch_decode(outputs)    # 将生成的 token IDs 转换为文本（字符串）\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:19:05.163507Z","iopub.execute_input":"2025-02-28T03:19:05.163812Z","iopub.status.idle":"2025-02-28T03:19:35.638160Z","shell.execute_reply.started":"2025-02-28T03:19:05.163787Z","shell.execute_reply":"2025-02-28T03:19:35.637226Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so let's think about this. We have a 61-year-old woman who's been dealing with involuntary urine loss during things like coughing or sneezing, but she's not leaking at night. That suggests she might have some kind of problem with her pelvic floor muscles or maybe her bladder.\n\nNow, she's got a gynecological exam and a Q-tip test. Let's break that down. The Q-tip test is usually used to check for urethral obstruction. If it's positive, that means there's something blocking the urethra, like a urethral stricture or something else.\n\nGiven that she's had a positive Q-tip test, it's likely there's a urethral obstruction. That would mean her urethra is narrow, maybe due to a stricture or some kind of narrowing. So, her bladder can't empty properly during activities like coughing because the urethral obstruction is making it hard.\n\nNow, let's think about what happens when her bladder can't empty. If there's a urethral obstruction, the bladder is forced to hold more urine, increasing the residual volume. That's because her bladder doesn't empty completely. So, her residual volume is probably increased.\n\nAlso, if her bladder can't empty properly, she might have increased detrusor contractions. These contractions are usually stronger to push the urine out. So, we expect her detrusor contractions to be increased.\n\nPutting it all together, if she has a urethral obstruction and a positive Q-tip test, we'd expect her cystometry results to show increased residual volume and increased detrusor contractions. That makes sense because of the obstruction and how her bladder is trying to compensate by contracting more.\n</think>\nBased on the findings of the gynecological exam and the positive Q-tip test, it is most likely that the cystometry would reveal increased residual volume and increased detrusor contractions. The positive Q-tip test indicates urethral obstruction, which would force the bladder to retain more urine, thereby increasing the residual volume. Additionally, the obstruction can lead to increased detrusor contractions as the bladder tries to compensate by contracting more to expel the urine.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"new_model_local = \"DeepSeek-R1-Medical\"\nmodel.save_pretrained(new_model_local) \ntokenizer.save_pretrained(new_model_local)\n\nmodel.save_pretrained_merged(new_model_local, tokenizer, save_method = \"merged_16bit\",)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:20:03.064485Z","iopub.execute_input":"2025-02-28T03:20:03.064810Z","iopub.status.idle":"2025-02-28T03:22:08.954887Z","shell.execute_reply.started":"2025-02-28T03:20:03.064784Z","shell.execute_reply":"2025-02-28T03:22:08.954213Z"}},"outputs":[{"name":"stderr","text":"Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\nWe shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\nTo force `safe_serialization`, set it to `None` instead.\nUnsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\nmodel which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\nUnsloth: Will remove a cached repo with size 6.0G\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 18.45 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":" 31%|███▏      | 10/32 [00:00<00:01, 14.24it/s]\nWe will save to Disk and not RAM now.\n100%|██████████| 32/32 [00:25<00:00,  1.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer... Done.\nUnsloth: Saving DeepSeek-R1-Medical/pytorch_model-00001-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-Medical/pytorch_model-00002-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-Medical/pytorch_model-00003-of-00004.bin...\nUnsloth: Saving DeepSeek-R1-Medical/pytorch_model-00004-of-00004.bin...\nDone.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"new_model_online = \"luyou042/DeepSeek-R1-Medical-demo\"\nmodel.push_to_hub(new_model_online)\ntokenizer.push_to_hub(new_model_online)\n\nmodel.push_to_hub_merged(new_model_online, tokenizer, save_method = \"merged_16bit\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T03:28:22.745496Z","iopub.execute_input":"2025-02-28T03:28:22.745788Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06748aecf0694e5cabc7d1d178ab9fdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82bbaeaa80ed485b9421ad8212be81eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9678193273c04574af124e24726faeea"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/luyou042/DeepSeek-R1-Medical-demo\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17baf651089a4d2e9c55e3235c358a51"}},"metadata":{}},{"name":"stderr","text":"Unsloth: You are pushing to hub in Kaggle environment.\nTo save memory, we shall move luyou042/DeepSeek-R1-Medical-demo to /tmp/DeepSeek-R1-Medical-demo\nUnsloth: Will remove a cached repo with size 1.6K\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 18.41 out of 31.35 RAM for saving.\nUnsloth: Saving model... This might take 5 minutes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32/32 [00:24<00:00,  1.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Saving tokenizer...","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":" Done.\nUnsloth: Saving /tmp/DeepSeek-R1-Medical-demo/pytorch_model-00001-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-Medical-demo/pytorch_model-00002-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-Medical-demo/pytorch_model-00003-of-00004.bin...\nUnsloth: Saving /tmp/DeepSeek-R1-Medical-demo/pytorch_model-00004-of-00004.bin...\n","output_type":"stream"}],"execution_count":null}]}